{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T06:19:05.265187Z",
     "start_time": "2024-05-08T06:19:05.258334Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from PIL import Image, ImageOps\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diamond/rightofway: 282 images\n",
      "hex/stop: 43 images\n",
      "square/laneend: 118 images\n",
      "square/parking: 276 images\n",
      "square/continue: 199 images\n",
      "square/crossing: 95 images\n",
      "triangle/giveway: 231 images\n",
      "triangle/warning: 695 images\n",
      "round/traveldirection: 124 images\n",
      "round/limitedtraffic: 125 images\n",
      "round/speed: 316 images\n",
      "round/roundabout: 98 images\n",
      "round/noentry: 375 images\n",
      "round/noparking: 242 images\n",
      "round/bicycle: 285 images\n",
      "round/trafficdirective: 195 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "# 图片所在的根目录\n",
    "root_dir = 'trafficsigns_dataset'  # 请替换成实际的路径\n",
    "\n",
    "# 用于存储按两层标签分隔的图片的嵌套字典\n",
    "images_by_label = {}\n",
    "\n",
    "# 用于遍历数据集并加载图像及其标签的函数\n",
    "def load_images_and_labels(root_dir):\n",
    "    # 遍历根目录下的每个子目录（第一层）\n",
    "    for sub_dir in os.listdir(root_dir):\n",
    "        sub_dir_path = os.path.join(root_dir, sub_dir)\n",
    "        \n",
    "        # 如果子目录确实是一个目录\n",
    "        if os.path.isdir(sub_dir_path):\n",
    "            # 初始化第一层标签键\n",
    "            images_by_label[sub_dir] = {}\n",
    "            \n",
    "            # 再次遍历该子目录下的文件夹（第二层，具体的标签）\n",
    "            for label_dir in os.listdir(sub_dir_path):\n",
    "                label_dir_path = os.path.join(sub_dir_path, label_dir)\n",
    "                \n",
    "                # 如果第二层也是一个目录\n",
    "                if os.path.isdir(label_dir_path):\n",
    "                    # 初始化第二层标签键\n",
    "                    images_by_label[sub_dir][label_dir] = []\n",
    "                    \n",
    "                    # 遍历第二层目录下的所有图像文件\n",
    "                    for image_filename in os.listdir(label_dir_path):\n",
    "                        # 忽略 .DS_Store 文件\n",
    "                        if image_filename == '.DS_Store':\n",
    "                            continue\n",
    "                        image_path = os.path.join(label_dir_path, image_filename)\n",
    "                        try:\n",
    "                            images_by_label[sub_dir][label_dir].append(image_path)\n",
    "                        except UnidentifiedImageError:\n",
    "                            # 如果无法识别图像，打印出错信息\n",
    "                            print(f\"Cannot identify image file '{image_path}'\")\n",
    "\n",
    "# 载入图像数据和标签\n",
    "load_images_and_labels(root_dir)\n",
    "\n",
    "# 打印每个类别的图像数量\n",
    "for sub_dir, labels in images_by_label.items():\n",
    "    for label, images in labels.items():\n",
    "        print(f\"{sub_dir}/{label}: {len(images)} images\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T06:19:05.313913Z",
     "start_time": "2024-05-08T06:19:05.291717Z"
    }
   },
   "id": "c40004f61bf99a5e",
   "execution_count": 323
  },
  {
   "cell_type": "markdown",
   "source": [
    "28no Unusual"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40e278730fffa660"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(array([28, 28]),\n array([28, 28]),\n array([28., 28.]),\n array([0., 0.]),\n array([28., 28.]))"
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_image_sizes(root_dir):\n",
    "    sizes = []\n",
    "    for subdir, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.png') or file.lower().endswith('.jpg'):\n",
    "                try:\n",
    "                    with Image.open(os.path.join(subdir, file)) as img:\n",
    "                        sizes.append(img.size)\n",
    "                except (IOError, UnidentifiedImageError):\n",
    "                    continue\n",
    "    return sizes\n",
    "\n",
    "image_sizes = get_image_sizes(root_dir)\n",
    "\n",
    "sizes_np = np.array(image_sizes)\n",
    "min_size = sizes_np.min(axis=0)\n",
    "max_size = sizes_np.max(axis=0)\n",
    "mean_size = sizes_np.mean(axis=0)\n",
    "std_dev_size = sizes_np.std(axis=0)\n",
    "median_size = np.median(sizes_np, axis=0)\n",
    "\n",
    "min_size, max_size, mean_size, std_dev_size, median_size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T06:19:05.577804Z",
     "start_time": "2024-05-08T06:19:05.315263Z"
    }
   },
   "id": "3d99edaca6000388",
   "execution_count": 324
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data = {}\n",
    "test_data = {}\n",
    "validation_data = {}\n",
    "\n",
    "for first_level, second_level_dict in images_by_label.items():\n",
    "    train_data[first_level] = {}\n",
    "    validation_data[first_level] = {}\n",
    "    test_data[first_level] = {}\n",
    "    \n",
    "    for label, image_paths in second_level_dict.items():\n",
    "        temp_images, test_images = train_test_split(image_paths, test_size=0.2, random_state=42)\n",
    "        train_images, val_images = train_test_split(temp_images, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Save split data\n",
    "        train_data[first_level][label] = train_images\n",
    "        test_data[first_level][label] = test_images\n",
    "        validation_data[first_level][label] = val_images\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T06:19:05.600537Z",
     "start_time": "2024-05-08T06:19:05.578652Z"
    }
   },
   "id": "4af5407217aac036",
   "execution_count": 325
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_dataframe_for_16_class(data_dict):\n",
    "    rows = []\n",
    "    for first_level, second_level_dict in data_dict.items():\n",
    "        for label, image_paths in second_level_dict.items():\n",
    "            for path in image_paths:\n",
    "                rows.append({'ImagePath': path, 'Label': label})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def create_dataframe_for_5_class(data_dict):\n",
    "    rows = []\n",
    "    for first_level, second_level_dict in data_dict.items():\n",
    "        for label, image_paths in second_level_dict.items():\n",
    "            for path in image_paths:\n",
    "                rows.append({'ImagePath': path, 'Label': first_level})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "train_df = create_dataframe_for_16_class(train_data)\n",
    "test_df = create_dataframe_for_16_class(test_data)\n",
    "validation_df = create_dataframe_for_16_class(validation_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T06:19:05.612719Z",
     "start_time": "2024-05-08T06:19:05.602219Z"
    }
   },
   "id": "81bb5a737570cec9",
   "execution_count": 326
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "batch_size = 64"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T06:19:05.615376Z",
     "start_time": "2024-05-08T06:19:05.613479Z"
    }
   },
   "id": "c6b88c5bf5ffa53e",
   "execution_count": 327
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2358 validated image filenames belonging to 16 classes.\n",
      "Found 596 validated image filenames belonging to 16 classes.\n",
      "Found 745 validated image filenames belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='ImagePath',\n",
    "    y_col='Label',\n",
    "    color_mode='grayscale',\n",
    "    target_size=(28, 28),  \n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # 如果是多分类问题\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=validation_df,\n",
    "    x_col='ImagePath',\n",
    "    y_col='Label',\n",
    "    color_mode='grayscale',\n",
    "    target_size=(28, 28),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # 如果是多分类问题\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='ImagePath',\n",
    "    y_col='Label',\n",
    "    color_mode='grayscale',\n",
    "    target_size=(28, 28),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # 如果是多分类问题\n",
    "    shuffle=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T06:19:05.655773Z",
     "start_time": "2024-05-08T06:19:05.616223Z"
    }
   },
   "id": "884e9e93d868f8e7",
   "execution_count": 328
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transfer data to suit scikit-learn"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "877454311e7768fa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_data_from_generator(generator):\n",
    "    batches = []\n",
    "    labels = []\n",
    "    # 迭代生成器收集数据和标签\n",
    "    for batch, label in generator:\n",
    "        batches.append(batch)\n",
    "        labels.append(label)\n",
    "        if len(batches) >= len(generator):\n",
    "            break  # 确保不会无限迭代\n",
    "    return np.vstack(batches), np.vstack(labels)\n",
    "\n",
    "\n",
    "X_train, y_train = get_data_from_generator(train_generator)\n",
    "X_val, y_val = get_data_from_generator(val_generator)\n",
    "X_test, y_test = get_data_from_generator(test_generator)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T06:19:05.930509Z",
     "start_time": "2024-05-08T06:19:05.656909Z"
    }
   },
   "id": "5f10df176fc1dd9f",
   "execution_count": 329
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1209cf946c70c032"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7466442953020134\n"
     ]
    }
   ],
   "source": [
    "# 假设X_train和X_val原始形状为[样本数, 28, 28, 1] - 例如从图像生成器中提取的\n",
    "\n",
    "# 重塑X_train和X_val为二维数组，每个图像一行\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)  # -1会根据剩余维度计算所需大小\n",
    "X_val = X_val.reshape(X_val.shape[0], -1)\n",
    "\n",
    "# 如果使用get_data_from_generator函数提取数据，确保先调整函数或数据后重塑\n",
    "# 示例，确保数据从生成器正确提取和转换后\n",
    "X_train, y_train = get_data_from_generator(train_generator)\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "\n",
    "X_val, y_val = get_data_from_generator(val_generator)\n",
    "X_val = X_val.reshape(X_val.shape[0], -1)\n",
    "\n",
    "# 训练决策树模型\n",
    "tree_model = DecisionTreeClassifier(max_depth=10)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# 在验证集上评估模型\n",
    "y_pred_val = tree_model.predict(X_val)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred_val))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T06:19:07.274014Z",
     "start_time": "2024-05-08T06:19:05.931318Z"
    }
   },
   "id": "7895d92f233236fd",
   "execution_count": 330
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75f95aefd73120a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7684563758389261\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 初始化随机森林模型\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=100, random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 使用验证集进行模型评估\n",
    "y_pred_val = rf_model.predict(X_val)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred_val))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T06:19:10.848159Z",
     "start_time": "2024-05-08T06:19:07.274932Z"
    }
   },
   "id": "f821800acc59950",
   "execution_count": 331
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55b54b0bc5e17795"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9379194630872483\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 假设 y_train 和 y_val 是 one-hot 编码的，形状为 (样本数, 类别数)\n",
    "y_train = np.argmax(y_train, axis=1)\n",
    "y_val = np.argmax(y_val, axis=1)\n",
    "\n",
    "# 初始化并应用标准化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# 初始化 SVM 模型\n",
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='auto', max_iter=1000)\n",
    "\n",
    "# 训练 SVM 模型\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 在验证集上评估 SVM 模型\n",
    "y_pred_val = svm_model.predict(X_val_scaled)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred_val))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T06:19:12.091238Z",
     "start_time": "2024-05-08T06:19:10.850823Z"
    }
   },
   "id": "5f11ad80c53197d6",
   "execution_count": 332
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MLP Baseline Model for Multi-class Task\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcdf7a88a258cb20"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "num_classes = 16\n",
    "input_shape = (28, 28)\n",
    "baseline_categorical = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=input_shape),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T06:19:12.140188Z",
     "start_time": "2024-05-08T06:19:12.091895Z"
    }
   },
   "id": "a6180087b0d2f017",
   "execution_count": 333
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "baseline_categorical.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=tf.keras.optimizers.Adam(),\n",
    "                        metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T06:19:12.148068Z",
     "start_time": "2024-05-08T06:19:12.141111Z"
    }
   },
   "id": "ff80e05c52d755ba",
   "execution_count": 334
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianbai/anaconda3/envs/DL/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 53ms/step - accuracy: 0.3657 - loss: 2.1895 - val_accuracy: 0.7651 - val_loss: 1.0377\n",
      "Epoch 2/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - accuracy: 0.7660 - loss: 0.9662 - val_accuracy: 0.8859 - val_loss: 0.6385\n",
      "Epoch 3/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - accuracy: 0.8624 - loss: 0.6197 - val_accuracy: 0.8943 - val_loss: 0.5007\n",
      "Epoch 4/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - accuracy: 0.8979 - loss: 0.4958 - val_accuracy: 0.9111 - val_loss: 0.4385\n",
      "Epoch 5/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - accuracy: 0.9011 - loss: 0.4347 - val_accuracy: 0.9329 - val_loss: 0.3573\n",
      "Epoch 6/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - accuracy: 0.9323 - loss: 0.3251 - val_accuracy: 0.9245 - val_loss: 0.3512\n",
      "Epoch 7/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9350 - loss: 0.3053 - val_accuracy: 0.9346 - val_loss: 0.3083\n",
      "Epoch 8/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9360 - loss: 0.2738 - val_accuracy: 0.9312 - val_loss: 0.3078\n",
      "Epoch 9/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9527 - loss: 0.2425 - val_accuracy: 0.9564 - val_loss: 0.2394\n",
      "Epoch 10/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9570 - loss: 0.2195 - val_accuracy: 0.9463 - val_loss: 0.2459\n",
      "Epoch 11/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9643 - loss: 0.1770 - val_accuracy: 0.9329 - val_loss: 0.2822\n",
      "Epoch 12/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - accuracy: 0.9697 - loss: 0.1806 - val_accuracy: 0.9497 - val_loss: 0.2282\n",
      "Epoch 13/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9708 - loss: 0.1541 - val_accuracy: 0.9463 - val_loss: 0.2282\n",
      "Epoch 14/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9776 - loss: 0.1325 - val_accuracy: 0.9497 - val_loss: 0.2174\n",
      "Epoch 15/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9745 - loss: 0.1299 - val_accuracy: 0.9530 - val_loss: 0.1999\n",
      "Epoch 16/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9671 - loss: 0.1382 - val_accuracy: 0.9463 - val_loss: 0.2329\n",
      "Epoch 17/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9836 - loss: 0.1036 - val_accuracy: 0.9530 - val_loss: 0.2088\n",
      "Epoch 18/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9750 - loss: 0.1188 - val_accuracy: 0.9564 - val_loss: 0.2095\n",
      "Epoch 19/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9803 - loss: 0.0920 - val_accuracy: 0.9547 - val_loss: 0.1861\n",
      "Epoch 20/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9851 - loss: 0.0921 - val_accuracy: 0.9513 - val_loss: 0.1977\n",
      "Epoch 21/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9839 - loss: 0.0894 - val_accuracy: 0.9614 - val_loss: 0.1730\n",
      "Epoch 22/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9875 - loss: 0.0753 - val_accuracy: 0.9513 - val_loss: 0.1943\n",
      "Epoch 23/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 20ms/step - accuracy: 0.9918 - loss: 0.0696 - val_accuracy: 0.9664 - val_loss: 0.1680\n",
      "Epoch 24/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9951 - loss: 0.0528 - val_accuracy: 0.9597 - val_loss: 0.1805\n",
      "Epoch 25/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9937 - loss: 0.0613 - val_accuracy: 0.9530 - val_loss: 0.1807\n",
      "Epoch 26/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9856 - loss: 0.0708 - val_accuracy: 0.9581 - val_loss: 0.1756\n",
      "Epoch 27/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9924 - loss: 0.0603 - val_accuracy: 0.9530 - val_loss: 0.1863\n",
      "Epoch 28/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9900 - loss: 0.0553 - val_accuracy: 0.9614 - val_loss: 0.1762\n",
      "Epoch 29/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9953 - loss: 0.0406 - val_accuracy: 0.9564 - val_loss: 0.1703\n",
      "Epoch 30/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9968 - loss: 0.0358 - val_accuracy: 0.9648 - val_loss: 0.1792\n",
      "Epoch 31/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9938 - loss: 0.0437 - val_accuracy: 0.9648 - val_loss: 0.1736\n",
      "Epoch 32/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9932 - loss: 0.0413 - val_accuracy: 0.9597 - val_loss: 0.1555\n",
      "Epoch 33/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 20ms/step - accuracy: 0.9955 - loss: 0.0462 - val_accuracy: 0.9513 - val_loss: 0.1794\n",
      "Epoch 34/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9926 - loss: 0.0394 - val_accuracy: 0.9497 - val_loss: 0.1942\n",
      "Epoch 35/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 20ms/step - accuracy: 0.9943 - loss: 0.0359 - val_accuracy: 0.9564 - val_loss: 0.1985\n",
      "Epoch 36/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9969 - loss: 0.0330 - val_accuracy: 0.9581 - val_loss: 0.2000\n",
      "Epoch 37/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9991 - loss: 0.0234 - val_accuracy: 0.9648 - val_loss: 0.1615\n",
      "Epoch 38/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 20ms/step - accuracy: 0.9980 - loss: 0.0219 - val_accuracy: 0.9648 - val_loss: 0.1627\n",
      "Epoch 39/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9995 - loss: 0.0174 - val_accuracy: 0.9614 - val_loss: 0.1809\n",
      "Epoch 40/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9966 - loss: 0.0233 - val_accuracy: 0.9564 - val_loss: 0.1815\n",
      "Epoch 41/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9984 - loss: 0.0229 - val_accuracy: 0.9530 - val_loss: 0.1714\n",
      "Epoch 42/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 20ms/step - accuracy: 0.9976 - loss: 0.0209 - val_accuracy: 0.9664 - val_loss: 0.1588\n",
      "Epoch 43/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9994 - loss: 0.0164 - val_accuracy: 0.9681 - val_loss: 0.1566\n",
      "Epoch 44/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9995 - loss: 0.0139 - val_accuracy: 0.9631 - val_loss: 0.1678\n",
      "Epoch 45/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 20ms/step - accuracy: 1.0000 - loss: 0.0141 - val_accuracy: 0.9664 - val_loss: 0.1600\n",
      "Epoch 46/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9994 - loss: 0.0152 - val_accuracy: 0.9631 - val_loss: 0.1645\n",
      "Epoch 47/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9990 - loss: 0.0140 - val_accuracy: 0.9681 - val_loss: 0.1559\n",
      "Epoch 48/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 0.9564 - val_loss: 0.1782\n",
      "Epoch 49/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9996 - loss: 0.0137 - val_accuracy: 0.9581 - val_loss: 0.1791\n",
      "Epoch 50/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - accuracy: 0.9976 - loss: 0.0139 - val_accuracy: 0.9564 - val_loss: 0.1897\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "history_baseline_categorical = baseline_categorical.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=epochs\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T06:19:55.214334Z",
     "start_time": "2024-05-08T06:19:12.148886Z"
    }
   },
   "id": "62f364fc639515de",
   "execution_count": 335
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modify images to make classify more difficult"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad50f039b6a03637"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2358 validated image filenames belonging to 16 classes.\n",
      "Found 596 validated image filenames belonging to 16 classes.\n",
      "Found 745 validated image filenames belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,  # 旋转范围（角度），可以调整范围，如 20-40\n",
    "    width_shift_range=0.1,  # 横向平移范围\n",
    "    height_shift_range=0.1,  # 纵向平移范围\n",
    "    shear_range=0.1,  # 剪切范围\n",
    "    zoom_range=0.1,  # 缩放范围\n",
    "    horizontal_flip=True,  # 水平翻转\n",
    ")\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='ImagePath',\n",
    "    y_col='Label',\n",
    "    color_mode='grayscale',\n",
    "    target_size=(28, 28),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=validation_df,\n",
    "    x_col='ImagePath',\n",
    "    y_col='Label',\n",
    "    color_mode='grayscale',\n",
    "    target_size=(28, 28),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='ImagePath',\n",
    "    y_col='Label',\n",
    "    color_mode='grayscale',\n",
    "    target_size=(28, 28),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  \n",
    "    shuffle=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T06:19:55.260678Z",
     "start_time": "2024-05-08T06:19:55.215300Z"
    }
   },
   "id": "f47c7851a1f2174",
   "execution_count": 336
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVM Model with modified dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47b7364530c6ea73"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7063758389261745\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def get_data_from_generator(generator):\n",
    "    batches = []\n",
    "    labels = []\n",
    "    # 迭代生成器收集数据和标签\n",
    "    for batch, label in generator:\n",
    "        batches.append(batch)\n",
    "        labels.append(label)\n",
    "        if len(batches) >= len(generator):\n",
    "            break  # 确保不会无限迭代\n",
    "    return np.vstack(batches), np.vstack(labels)\n",
    "\n",
    "X_train, y_train = get_data_from_generator(train_generator)\n",
    "X_val, y_val = get_data_from_generator(val_generator)\n",
    "X_test, y_test = get_data_from_generator(test_generator)\n",
    "\n",
    "# 重塑数据以适应 StandardScaler 的输入需求\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_val = X_val.reshape(X_val.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# 假设 y_train 和 y_val 是 one-hot 编码的，形状为 (样本数, 类别数)\n",
    "y_train = np.argmax(y_train, axis=1)\n",
    "y_val = np.argmax(y_val, axis=1)\n",
    "\n",
    "# 初始化并应用标准化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# 初始化 SVM 模型\n",
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='auto', max_iter=1000)\n",
    "\n",
    "# 训练 SVM 模型\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 在验证集上评估 SVM 模型\n",
    "y_pred_val = svm_model.predict(X_val_scaled)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred_val))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T06:19:57.555017Z",
     "start_time": "2024-05-08T06:19:55.261504Z"
    }
   },
   "id": "31e046e164eed392",
   "execution_count": 337
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MLP Model with modified dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2e66e0b80469ca8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "num_classes = 16\n",
    "input_shape = (28, 28)\n",
    "baseline_categorical = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=input_shape),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T06:19:57.575250Z",
     "start_time": "2024-05-08T06:19:57.555728Z"
    }
   },
   "id": "f61501bd7fe5caae",
   "execution_count": 338
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "baseline_categorical.compile(loss='binary_crossentropy',\n",
    "                        optimizer=tf.keras.optimizers.Adam(),\n",
    "                        metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T06:19:57.580776Z",
     "start_time": "2024-05-08T06:19:57.576067Z"
    }
   },
   "id": "c611d24a60fadf75",
   "execution_count": 339
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianbai/anaconda3/envs/DL/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 56ms/step - accuracy: 0.1752 - loss: 0.3059 - val_accuracy: 0.3154 - val_loss: 0.2028\n",
      "Epoch 2/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 18ms/step - accuracy: 0.3131 - loss: 0.2156 - val_accuracy: 0.4413 - val_loss: 0.1769\n",
      "Epoch 3/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 16ms/step - accuracy: 0.3754 - loss: 0.1986 - val_accuracy: 0.5369 - val_loss: 0.1641\n",
      "Epoch 4/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - accuracy: 0.4152 - loss: 0.1881 - val_accuracy: 0.5772 - val_loss: 0.1541\n",
      "Epoch 5/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 16ms/step - accuracy: 0.4211 - loss: 0.1828 - val_accuracy: 0.5487 - val_loss: 0.1528\n",
      "Epoch 6/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 16ms/step - accuracy: 0.4593 - loss: 0.1741 - val_accuracy: 0.6057 - val_loss: 0.1424\n",
      "Epoch 7/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - accuracy: 0.4767 - loss: 0.1746 - val_accuracy: 0.5889 - val_loss: 0.1418\n",
      "Epoch 8/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 16ms/step - accuracy: 0.4729 - loss: 0.1733 - val_accuracy: 0.6628 - val_loss: 0.1344\n",
      "Epoch 9/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - accuracy: 0.4949 - loss: 0.1655 - val_accuracy: 0.6745 - val_loss: 0.1277\n",
      "Epoch 10/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - accuracy: 0.4914 - loss: 0.1641 - val_accuracy: 0.6611 - val_loss: 0.1263\n",
      "Epoch 11/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - accuracy: 0.5112 - loss: 0.1590 - val_accuracy: 0.7081 - val_loss: 0.1193\n",
      "Epoch 12/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - accuracy: 0.5084 - loss: 0.1562 - val_accuracy: 0.6896 - val_loss: 0.1184\n",
      "Epoch 13/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - accuracy: 0.5415 - loss: 0.1533 - val_accuracy: 0.7013 - val_loss: 0.1166\n",
      "Epoch 14/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - accuracy: 0.5331 - loss: 0.1526 - val_accuracy: 0.7131 - val_loss: 0.1132\n",
      "Epoch 15/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - accuracy: 0.5580 - loss: 0.1452 - val_accuracy: 0.6997 - val_loss: 0.1102\n",
      "Epoch 16/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - accuracy: 0.5574 - loss: 0.1466 - val_accuracy: 0.6896 - val_loss: 0.1107\n",
      "Epoch 17/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - accuracy: 0.5327 - loss: 0.1471 - val_accuracy: 0.7081 - val_loss: 0.1081\n",
      "Epoch 18/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - accuracy: 0.5841 - loss: 0.1389 - val_accuracy: 0.7332 - val_loss: 0.1036\n",
      "Epoch 19/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - accuracy: 0.5628 - loss: 0.1441 - val_accuracy: 0.7299 - val_loss: 0.1012\n",
      "Epoch 20/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - accuracy: 0.5988 - loss: 0.1366 - val_accuracy: 0.7383 - val_loss: 0.1015\n",
      "Epoch 21/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - accuracy: 0.5955 - loss: 0.1373 - val_accuracy: 0.7366 - val_loss: 0.0984\n",
      "Epoch 22/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - accuracy: 0.5944 - loss: 0.1318 - val_accuracy: 0.7752 - val_loss: 0.0950\n",
      "Epoch 23/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - accuracy: 0.6044 - loss: 0.1312 - val_accuracy: 0.7500 - val_loss: 0.0952\n",
      "Epoch 24/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - accuracy: 0.5964 - loss: 0.1322 - val_accuracy: 0.7584 - val_loss: 0.0940\n",
      "Epoch 25/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - accuracy: 0.5977 - loss: 0.1310 - val_accuracy: 0.7735 - val_loss: 0.0936\n",
      "Epoch 26/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - accuracy: 0.6142 - loss: 0.1281 - val_accuracy: 0.7617 - val_loss: 0.0905\n",
      "Epoch 27/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - accuracy: 0.6081 - loss: 0.1306 - val_accuracy: 0.7836 - val_loss: 0.0890\n",
      "Epoch 28/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - accuracy: 0.6378 - loss: 0.1216 - val_accuracy: 0.7735 - val_loss: 0.0885\n",
      "Epoch 29/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - accuracy: 0.6230 - loss: 0.1257 - val_accuracy: 0.7768 - val_loss: 0.0859\n",
      "Epoch 30/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - accuracy: 0.6135 - loss: 0.1212 - val_accuracy: 0.7651 - val_loss: 0.0887\n",
      "Epoch 31/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - accuracy: 0.6447 - loss: 0.1229 - val_accuracy: 0.7836 - val_loss: 0.0844\n",
      "Epoch 32/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - accuracy: 0.6354 - loss: 0.1198 - val_accuracy: 0.7550 - val_loss: 0.0858\n",
      "Epoch 33/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - accuracy: 0.6470 - loss: 0.1204 - val_accuracy: 0.7651 - val_loss: 0.0868\n",
      "Epoch 34/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - accuracy: 0.6469 - loss: 0.1180 - val_accuracy: 0.7752 - val_loss: 0.0836\n",
      "Epoch 35/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - accuracy: 0.6580 - loss: 0.1144 - val_accuracy: 0.7718 - val_loss: 0.0803\n",
      "Epoch 36/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - accuracy: 0.6540 - loss: 0.1158 - val_accuracy: 0.7936 - val_loss: 0.0823\n",
      "Epoch 37/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - accuracy: 0.6599 - loss: 0.1140 - val_accuracy: 0.7936 - val_loss: 0.0789\n",
      "Epoch 38/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - accuracy: 0.6692 - loss: 0.1119 - val_accuracy: 0.7886 - val_loss: 0.0793\n",
      "Epoch 39/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - accuracy: 0.6439 - loss: 0.1165 - val_accuracy: 0.7752 - val_loss: 0.0814\n",
      "Epoch 40/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - accuracy: 0.6659 - loss: 0.1126 - val_accuracy: 0.7953 - val_loss: 0.0793\n",
      "Epoch 41/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - accuracy: 0.6576 - loss: 0.1077 - val_accuracy: 0.7953 - val_loss: 0.0798\n",
      "Epoch 42/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - accuracy: 0.6644 - loss: 0.1109 - val_accuracy: 0.7852 - val_loss: 0.0812\n",
      "Epoch 43/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - accuracy: 0.6676 - loss: 0.1106 - val_accuracy: 0.7903 - val_loss: 0.0782\n",
      "Epoch 44/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - accuracy: 0.6897 - loss: 0.1066 - val_accuracy: 0.7987 - val_loss: 0.0750\n",
      "Epoch 45/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - accuracy: 0.6810 - loss: 0.1089 - val_accuracy: 0.8121 - val_loss: 0.0749\n",
      "Epoch 46/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - accuracy: 0.7023 - loss: 0.1049 - val_accuracy: 0.8020 - val_loss: 0.0751\n",
      "Epoch 47/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - accuracy: 0.6971 - loss: 0.1051 - val_accuracy: 0.8054 - val_loss: 0.0738\n",
      "Epoch 48/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - accuracy: 0.6969 - loss: 0.1043 - val_accuracy: 0.8070 - val_loss: 0.0723\n",
      "Epoch 49/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - accuracy: 0.7126 - loss: 0.1015 - val_accuracy: 0.8138 - val_loss: 0.0720\n",
      "Epoch 50/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - accuracy: 0.6847 - loss: 0.1061 - val_accuracy: 0.8121 - val_loss: 0.0713\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "history_baseline_categorical = baseline_categorical.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=epochs\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T06:20:32.054726Z",
     "start_time": "2024-05-08T06:19:57.581768Z"
    }
   },
   "id": "e2baac02dc62a81",
   "execution_count": 340
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CNN Model for Multi Class"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14298899e4ac5677"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "num_classes = 16  # 根据你的任务调整类别数\n",
    "\n",
    "cnn_model = models.Sequential([\n",
    "    layers.Input(shape=(28, 28, 1)),  # 灰度图像输入，1 个通道\n",
    "    layers.Conv2D(32, (3, 3), padding='same'),  # 第一卷积层，32 个滤波器\n",
    "    layers.BatchNormalization(),  # 添加批归一化\n",
    "    layers.Activation('relu'),  # 激活层\n",
    "    layers.MaxPooling2D((2, 2)),  # 最大池化\n",
    "    layers.Conv2D(64, (3, 3), padding='same'),  # 第二卷积层，64 个滤波器\n",
    "    layers.BatchNormalization(),  # 添加批归一化\n",
    "    layers.Activation('relu'),  # 激活层\n",
    "    layers.MaxPooling2D((2, 2)),  # 最大池化\n",
    "    layers.Conv2D(128, (3, 3), padding='same'),  # 第三卷积层，128 个滤波器\n",
    "    layers.BatchNormalization(),  # 添加批归一化\n",
    "    layers.Activation('relu'),  # 激活层\n",
    "    layers.MaxPooling2D((2, 2)),  # 最大池化\n",
    "    layers.Flatten(),  # 将卷积结果展平\n",
    "    layers.Dense(512),  # 全连接层\n",
    "    layers.BatchNormalization(),  # 添加批归一化\n",
    "    layers.Activation('relu'),  # 激活层\n",
    "    layers.Dense(num_classes, activation='softmax')  # 输出层，使用 softmax 激活\n",
    "])\n",
    "\n",
    "cnn_model.compile(\n",
    "    loss='categorical_crossentropy',  # 使用多分类交叉熵损失\n",
    "    optimizer=tf.keras.optimizers.Adam(),  # Adam 优化器\n",
    "    metrics=['accuracy']  # 使用准确率作为指标\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T06:20:32.125288Z",
     "start_time": "2024-05-08T06:20:32.055598Z"
    }
   },
   "id": "9e47a934164fc830",
   "execution_count": 341
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 199ms/step - accuracy: 0.4646 - loss: 1.8736 - val_accuracy: 0.1191 - val_loss: 2.7801\n",
      "Epoch 2/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 52ms/step - accuracy: 0.8578 - loss: 0.4872 - val_accuracy: 0.0822 - val_loss: 3.3375\n",
      "Epoch 3/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 51ms/step - accuracy: 0.8991 - loss: 0.3150 - val_accuracy: 0.0772 - val_loss: 4.1155\n",
      "Epoch 4/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 52ms/step - accuracy: 0.9279 - loss: 0.2529 - val_accuracy: 0.0856 - val_loss: 3.4767\n",
      "Epoch 5/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 51ms/step - accuracy: 0.9408 - loss: 0.2136 - val_accuracy: 0.1242 - val_loss: 3.6376\n",
      "Epoch 6/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 52ms/step - accuracy: 0.9454 - loss: 0.1680 - val_accuracy: 0.2148 - val_loss: 3.3484\n",
      "Epoch 7/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 49ms/step - accuracy: 0.9494 - loss: 0.1719 - val_accuracy: 0.3574 - val_loss: 2.1343\n",
      "Epoch 8/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 49ms/step - accuracy: 0.9699 - loss: 0.1073 - val_accuracy: 0.5587 - val_loss: 1.5199\n",
      "Epoch 9/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 49ms/step - accuracy: 0.9537 - loss: 0.1612 - val_accuracy: 0.6191 - val_loss: 1.1610\n",
      "Epoch 10/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 48ms/step - accuracy: 0.9684 - loss: 0.1080 - val_accuracy: 0.7299 - val_loss: 0.9087\n",
      "Epoch 11/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 52ms/step - accuracy: 0.9744 - loss: 0.0960 - val_accuracy: 0.8003 - val_loss: 0.5943\n",
      "Epoch 12/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 52ms/step - accuracy: 0.9749 - loss: 0.0945 - val_accuracy: 0.8725 - val_loss: 0.3433\n",
      "Epoch 13/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 47ms/step - accuracy: 0.9755 - loss: 0.0801 - val_accuracy: 0.9262 - val_loss: 0.1968\n",
      "Epoch 14/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 48ms/step - accuracy: 0.9768 - loss: 0.0799 - val_accuracy: 0.9664 - val_loss: 0.1133\n",
      "Epoch 15/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 47ms/step - accuracy: 0.9799 - loss: 0.0716 - val_accuracy: 0.9681 - val_loss: 0.1176\n",
      "Epoch 16/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 48ms/step - accuracy: 0.9725 - loss: 0.0758 - val_accuracy: 0.9748 - val_loss: 0.1032\n",
      "Epoch 17/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 49ms/step - accuracy: 0.9695 - loss: 0.0992 - val_accuracy: 0.9849 - val_loss: 0.0490\n",
      "Epoch 18/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 48ms/step - accuracy: 0.9877 - loss: 0.0460 - val_accuracy: 0.9715 - val_loss: 0.0729\n",
      "Epoch 19/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 48ms/step - accuracy: 0.9900 - loss: 0.0456 - val_accuracy: 0.9883 - val_loss: 0.0381\n",
      "Epoch 20/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 48ms/step - accuracy: 0.9803 - loss: 0.0668 - val_accuracy: 0.9916 - val_loss: 0.0378\n",
      "Epoch 21/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 47ms/step - accuracy: 0.9834 - loss: 0.0569 - val_accuracy: 0.9899 - val_loss: 0.0327\n",
      "Epoch 22/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 48ms/step - accuracy: 0.9834 - loss: 0.0615 - val_accuracy: 0.9715 - val_loss: 0.0618\n",
      "Epoch 23/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 48ms/step - accuracy: 0.9934 - loss: 0.0376 - val_accuracy: 0.9849 - val_loss: 0.0379\n",
      "Epoch 24/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 47ms/step - accuracy: 0.9922 - loss: 0.0346 - val_accuracy: 0.9815 - val_loss: 0.0586\n",
      "Epoch 25/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 48ms/step - accuracy: 0.9858 - loss: 0.0477 - val_accuracy: 0.9849 - val_loss: 0.0397\n",
      "Epoch 26/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 48ms/step - accuracy: 0.9918 - loss: 0.0334 - val_accuracy: 0.9782 - val_loss: 0.0782\n",
      "Epoch 27/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 48ms/step - accuracy: 0.9880 - loss: 0.0426 - val_accuracy: 0.9899 - val_loss: 0.0278\n",
      "Epoch 28/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 50ms/step - accuracy: 0.9898 - loss: 0.0321 - val_accuracy: 0.9883 - val_loss: 0.0418\n",
      "Epoch 29/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 48ms/step - accuracy: 0.9891 - loss: 0.0343 - val_accuracy: 0.9748 - val_loss: 0.0642\n",
      "Epoch 30/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 49ms/step - accuracy: 0.9898 - loss: 0.0415 - val_accuracy: 0.9849 - val_loss: 0.0491\n",
      "Epoch 31/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 48ms/step - accuracy: 0.9891 - loss: 0.0374 - val_accuracy: 0.9748 - val_loss: 0.0776\n",
      "Epoch 32/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 47ms/step - accuracy: 0.9917 - loss: 0.0292 - val_accuracy: 0.9832 - val_loss: 0.0535\n",
      "Epoch 33/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 47ms/step - accuracy: 0.9953 - loss: 0.0205 - val_accuracy: 0.9883 - val_loss: 0.0317\n",
      "Epoch 34/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 47ms/step - accuracy: 0.9924 - loss: 0.0269 - val_accuracy: 0.9748 - val_loss: 0.0625\n",
      "Epoch 35/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 48ms/step - accuracy: 0.9875 - loss: 0.0425 - val_accuracy: 0.9849 - val_loss: 0.0406\n",
      "Epoch 36/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 47ms/step - accuracy: 0.9866 - loss: 0.0386 - val_accuracy: 0.9815 - val_loss: 0.0647\n",
      "Epoch 37/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 47ms/step - accuracy: 0.9944 - loss: 0.0208 - val_accuracy: 0.9899 - val_loss: 0.0435\n",
      "Epoch 38/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 47ms/step - accuracy: 0.9919 - loss: 0.0251 - val_accuracy: 0.9782 - val_loss: 0.0477\n",
      "Epoch 39/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 48ms/step - accuracy: 0.9915 - loss: 0.0277 - val_accuracy: 0.9832 - val_loss: 0.0526\n",
      "Epoch 40/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 49ms/step - accuracy: 0.9908 - loss: 0.0321 - val_accuracy: 0.9933 - val_loss: 0.0242\n",
      "Epoch 41/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 49ms/step - accuracy: 0.9905 - loss: 0.0277 - val_accuracy: 0.9832 - val_loss: 0.0510\n",
      "Epoch 42/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 51ms/step - accuracy: 0.9873 - loss: 0.0431 - val_accuracy: 0.9698 - val_loss: 0.1032\n",
      "Epoch 43/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 49ms/step - accuracy: 0.9883 - loss: 0.0368 - val_accuracy: 0.9732 - val_loss: 0.0797\n",
      "Epoch 44/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 48ms/step - accuracy: 0.9925 - loss: 0.0250 - val_accuracy: 0.9765 - val_loss: 0.0880\n",
      "Epoch 45/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 48ms/step - accuracy: 0.9914 - loss: 0.0259 - val_accuracy: 0.9950 - val_loss: 0.0165\n",
      "Epoch 46/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 48ms/step - accuracy: 0.9931 - loss: 0.0219 - val_accuracy: 0.9950 - val_loss: 0.0169\n",
      "Epoch 47/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 47ms/step - accuracy: 0.9932 - loss: 0.0299 - val_accuracy: 0.9681 - val_loss: 0.1360\n",
      "Epoch 48/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 47ms/step - accuracy: 0.9867 - loss: 0.0338 - val_accuracy: 0.9765 - val_loss: 0.0464\n",
      "Epoch 49/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 47ms/step - accuracy: 0.9888 - loss: 0.0333 - val_accuracy: 0.9732 - val_loss: 0.0649\n",
      "Epoch 50/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 47ms/step - accuracy: 0.9904 - loss: 0.0326 - val_accuracy: 0.9815 - val_loss: 0.0473\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "history_cnn = cnn_model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=epochs\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T06:22:15.314015Z",
     "start_time": "2024-05-08T06:20:32.126162Z"
    }
   },
   "id": "1e1892988de3c87d",
   "execution_count": 342
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
